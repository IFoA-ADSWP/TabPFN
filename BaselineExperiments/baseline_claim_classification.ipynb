{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597a309c",
   "metadata": {},
   "source": [
    "# Baselining: Claim Frequency -> Claim Occurrence (classification)\n",
    "\n",
    "This notebook converts a numeric `ClaimFrequency` target into a binary `HasClaim` target\n",
    "(0 = no claim, 1 = at least one claim) and runs a small set of baseline classifiers to\n",
    "benchmark performance using accuracy, F1 and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ed3b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports OK\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: core imports and config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# reproducibility & logging\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print('imports OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30cd625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using TabPFN package\n",
      "INFO:root:Using TabPFN package\n",
      "/Users/Scott/Documents/Data Science/ADSWP/.venv/lib/python3.12/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "\n",
    "# TabPFN and Extensions\n",
    "\n",
    "try:\n",
    "    from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
    "        AutoTabPFNClassifier,\n",
    "    )\n",
    "\n",
    "    from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Warning: Could not import TabPFN / TabPFN extensions. Please run installation above and restart the session afterwards (Runtime > Restart Session).\"\n",
    "    )\n",
    "\n",
    "# Data Science & Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Other ML Models\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# Notebook UI/Display\n",
    "from IPython.display import Markdown, display\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.prompt import Prompt\n",
    "from rich.rule import Rule\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "# Scikit-Learn: Data & Preprocessing\n",
    "from sklearn.datasets import fetch_openml, load_breast_cancer\n",
    "\n",
    "# Scikit-Learn: Models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# This transformer will be used to handle categorical features for the baseline models\n",
    "column_transformer = make_column_transformer(\n",
    "    (\n",
    "        OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "        make_column_selector(dtype_include=[\"object\", \"category\"]),\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5c7524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────╮\n",
       "│ <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TabPFN Demo: Backend Selection</span> │\n",
       "╰────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────╮\n",
       "│ \u001b[1;35mTabPFN Demo: Backend Selection\u001b[0m │\n",
       "╰────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "This script can run TabPFN using one of two backends:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "This script can run TabPFN using one of two backends:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">. local:</span> Uses a local GPU <span style=\"font-weight: bold\">(</span>NVIDIA<span style=\"font-weight: bold\">)</span>. Requires CUDA.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[1;36m1\u001b[0m\u001b[1m. local:\u001b[0m Uses a local GPU \u001b[1m(\u001b[0mNVIDIA\u001b[1m)\u001b[0m. Requires CUDA.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">. client:</span> Uses the TabPFN API. Requires an internet connection and a free account.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[1;36m2\u001b[0m\u001b[1m. client:\u001b[0m Uses the TabPFN API. Requires an internet connection and a free account.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Choose your backend</span> - If not field to enter is shown restart the cell. <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[client/local]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(client)</span>: </pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mChoose your backend\u001b[0m - If not field to enter is shown restart the cell. \u001b[1;35m[client/local]\u001b[0m \u001b[1;36m(client)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "✅ You have selected the <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">client</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> backend.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "✅ You have selected the \u001b[32m'\u001b[0m\u001b[1;32mclient\u001b[0m\u001b[32m'\u001b[0m backend.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────── </span><span style=\"font-weight: bold\">Setting up </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">client</span><span style=\"font-weight: bold\"> backend</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────── \u001b[0m\u001b[1mSetting up \u001b[0m\u001b[1;36mclient\u001b[0m\u001b[1m backend\u001b[0m\u001b[92m ────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Attempting client backend setup<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Attempting client backend setup\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Importing TabPFN client library<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Importing TabPFN client library\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Welcome Back! Found existing access token, reusing it for authentication.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ TabPFN (client) initialized.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ TabPFN \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mclient\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m initialized.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "\n",
    "console.print(Panel.fit(\"[bold magenta]TabPFN Demo: Backend Selection[/bold magenta]\"))\n",
    "console.print(\"\\nThis script can run TabPFN using one of two backends:\")\n",
    "console.print(\"  [bold]1. local:[/bold] Uses a local GPU (NVIDIA). Requires CUDA.\")\n",
    "console.print(\n",
    "    \"  [bold]2. client:[/bold] Uses the TabPFN API. Requires an internet connection and a free account.\"\n",
    ")\n",
    "\n",
    "backend = Prompt.ask(\n",
    "    \"\\n[bold]Choose your backend[/bold] - If not field to enter is shown restart the cell.\",\n",
    "    choices=[\"client\", \"local\"],\n",
    "    default=\"client\",\n",
    ")\n",
    "\n",
    "console.print(\n",
    "    f\"\\n✅ You have selected the '[bold green]{backend}[/bold green]' backend.\"\n",
    ")\n",
    "\n",
    "console.print(Rule(f\"[bold]Setting up [cyan]{backend}[/cyan] backend[/bold]\"))\n",
    "\n",
    "if backend == \"local\":\n",
    "    console.print(\"Attempting local backend setup...\")\n",
    "    import torch\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        console.print(\n",
    "            \"[bold red]Error:[/bold red] GPU device not found. For fast training, please enable GPU.\",\n",
    "            style=\"red\",\n",
    "        )\n",
    "        console.print(\n",
    "            \"In Colab: Go to [bold]Runtime -> Change runtime type -> Hardware accelerator -> GPU.[/bold]\",\n",
    "            style=\"yellow\",\n",
    "        )\n",
    "        raise SystemError(\"GPU device not found.\")\n",
    "    console.print(\n",
    "        \"[bold green]✅ GPU is available.[/bold green] Importing local TabPFN library...\"\n",
    "    )\n",
    "    from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "    console.print(\"[bold green]✅ TabPFN (local) imported successfully.[/bold green]\")\n",
    "elif backend == \"client\":\n",
    "    console.print(\"Attempting client backend setup...\")\n",
    "    console.print(\"Importing TabPFN client library...\")\n",
    "    from tabpfn_client import TabPFNClassifier, TabPFNRegressor, init\n",
    "\n",
    "    init()\n",
    "    console.print(\"[bold green]✅ TabPFN (client) initialized.[/bold green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4d130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: expected baselining dir at /Users/Scott/Documents/Data Science/ADSWP/BaselineDirectory/baselining\n",
      "importable: data_loader\n",
      "importable: model_training\n",
      "importable: evaluation_metrics\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ensure baselining directory is importable (robust)\n",
    "import sys, os, importlib\n",
    "from pathlib import Path\n",
    "\n",
    "nb_cwd = Path.cwd()\n",
    "# prefer a local `baselining/` sibling of the current working dir\n",
    "candidate = nb_cwd / 'baselining'\n",
    "if candidate.exists():\n",
    "    p = str(candidate)\n",
    "    if p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "        print('Inserted to sys.path:', p)\n",
    "    else:\n",
    "        print('Already in sys.path:', p)\n",
    "else:\n",
    "    print('Warning: expected baselining dir at', candidate)\n",
    "\n",
    "# quick import smoke-test for required modules\n",
    "for m in ('data_loader','model_training','evaluation_metrics'):\n",
    "    try:\n",
    "        importlib.import_module(m)\n",
    "        print('importable:', m)\n",
    "    except Exception as e:\n",
    "        print('not importable:', m, '-', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2b0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV: /Users/Scott/Documents/Data Science/ADSWP/TabPFN/ADSWP Project/baselining/data/freMTPL2freq.csv\n",
      "Using sample rows: 500 target column: ClaimNb HasClaim distribution: {0: 477, 1: 23}\n",
      "Split done. X_train: (400, 12) X_test: (100, 12)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: load and prepare classification data (sampled for faster iterations)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from data_loader import preprocess_data   # keep preprocess helper if you want to reuse it\n",
    "\n",
    "csv_path = Path(\"/Users/Scott/Documents Data Science/ADSWP/TabPFN/ADSWP Project/baselining/data/freMTPL2freq.csv\")\n",
    "if not csv_path.exists():\n",
    "    # try original path from notebook (handles spaces vs dots)\n",
    "    csv_path = Path(\"/Users/Scott/Documents/Data Science/ADSWP/TabPFN/ADSWP Project/baselining/data/freMTPL2freq.csv\")\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f\"CSV not found: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Sampling options\n",
    "sample_frac = None   # not used when sample_n is set\n",
    "sample_n = 500       # set to None to use full data\n",
    "\n",
    "# Robustly select a claim-count column\n",
    "candidate_names = [\n",
    "    \"ClaimFrequency\", \"ClaimNb\", \"NumberOfClaims\", \"NumberOfClaims\",\n",
    "    \"Claims\", \"Claim_Number\", \"ClaimNumber\", \"ClaimCount\"\n",
    "]\n",
    "target_col = next((c for c in candidate_names if c in df.columns), None)\n",
    "\n",
    "if target_col is None:\n",
    "    # fallback: any column containing 'claim' (case-insensitive)\n",
    "    matches = [c for c in df.columns if \"claim\" in c.lower()]\n",
    "    if len(matches) == 1:\n",
    "        target_col = matches[0]\n",
    "    elif len(matches) > 1:\n",
    "        # prefer frequency/number/count variants if present\n",
    "        for pref in (\"freq\", \"nb\", \"number\", \"count\"):\n",
    "            found = next((m for m in matches if pref in m.lower()), None)\n",
    "            if found:\n",
    "                target_col = found\n",
    "                break\n",
    "        if target_col is None:\n",
    "            target_col = matches[0]  # pick first if ambiguous\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(f\"Could not find a claim-count column. Columns checked: {candidate_names} and any column containing 'claim'.\")\n",
    "\n",
    "# create binary target: HasClaim = 1 if claim-count > 0 else 0\n",
    "df[\"HasClaim\"] = (df[target_col] > 0).astype(int)\n",
    "\n",
    "# take a sample for quicker iteration\n",
    "if sample_n is not None:\n",
    "    if sample_n < len(df):\n",
    "        df = df.sample(n=sample_n, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "else:\n",
    "    if sample_frac is not None and 0 < sample_frac < 1:\n",
    "        df = df.sample(frac=sample_frac, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"Loaded CSV:\", csv_path)\n",
    "print(\"Using sample rows:\", len(df), \"target column:\", target_col, \"HasClaim distribution:\", df[\"HasClaim\"].value_counts().to_dict())\n",
    "\n",
    "# split (reuse your existing preprocess_data)\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df, target=\"HasClaim\")\n",
    "print(\"Split done. X_train:\", X_train.shape, \"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926248b2",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline\n",
    "\n",
    "Define a ColumnTransformer for numeric and categorical features and a reusable `preprocessor` used by every model pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5657544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor ready — numeric: 8 cat: 4\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# auto-detect feature types from X_train (assumes X_train exists)\n",
    "numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# construct OneHotEncoder in a version-compatible way\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "except TypeError:\n",
    "    # newer sklearn uses `sparse_output` instead of `sparse`\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='__MISSING__')),\n",
    "    ('ohe', ohe)\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, numeric_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "print('Preprocessor ready — numeric:', len(numeric_cols), 'cat:', len(cat_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27029d",
   "metadata": {},
   "source": [
    "## Models and pipelines\n",
    "\n",
    "Create a small set of pipelines (preprocessor + estimator). Keep `class_weight='balanced'` where available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ec7a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined models: ['logistic', 'random_forest', 'grad_boost']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "models = {\n",
    "    'logistic': Pipeline([('pre', preprocessor), ('clf', LogisticRegression(max_iter=200, class_weight='balanced', random_state=RANDOM_SEED))]),\n",
    "    'random_forest': Pipeline([('pre', preprocessor), ('clf', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_SEED))]),\n",
    "    'grad_boost': Pipeline([('pre', preprocessor), ('clf', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_SEED))])\n",
    "}\n",
    "print('Defined models:', list(models.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a18f0",
   "metadata": {},
   "source": [
    "## TabPFN baseline (optional)\n",
    "\n",
    "Try to load the TabPFN classifier, fit on the training set, and add its predictions to the `preds` DataFrame. This cell is defensive: it skips if TabPFN isn't installed or if pretraining limits would be exceeded (but it can be forced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed101556",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (221135227.py, line 7)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m```bash\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Installation (run once outside the notebook)\n",
    "\n",
    "#This notebook expects the usual ML packages to be available in the environment (scikit-learn, pandas, numpy, joblib, matplotlib) and optionally TabPFN if you want to run the TabPFN baseline.\n",
    "\n",
    "#Run these commands in your terminal (not in the notebook) to prepare the environment:\n",
    "\n",
    "```bash\n",
    "# create / activate your venv, then:\n",
    "python -m pip install -U pip\n",
    "python -m pip install -r requirements.txt  # if you maintain one\n",
    "# or at minimum:\n",
    "python -m pip install scikit-learn pandas numpy joblib matplotlib\n",
    "# optional: TabPFN (use a scikit-learn compatible version, e.g. sklearn==1.2.2)\n",
    "python -m pip install \"scikit-learn==1.2.2\"\n",
    "python -m pip install tabpfn tabpfn-client\n",
    "```\n",
    "\n",
    "If you use Colab or other managed runtimes you may prefer the full install steps in the TabPFN repo; the notebook will check availability and skip TabPFN if it is not importable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dfed02df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabPFN import OK\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "\n",
    "# TabPFN and Extensions (defensive import)\n",
    "try:\n",
    "    from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
    "        AutoTabPFNClassifier,\n",
    "    )\n",
    "    from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "    tabpfn_available = True\n",
    "    print('TabPFN import OK')\n",
    "except Exception as e:\n",
    "    tabpfn_available = False\n",
    "    TabPFNClassifier = None\n",
    "    TabPFNRegressor = None\n",
    "    print('TabPFN not available - continuing without it. To enable TabPFN install it in your environment. Error:', e)\n",
    "\n",
    "# Data Science & Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Optional: torch may not be available in all environments\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "# Other ML Models (optional imports)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "except Exception:\n",
    "    CatBoostClassifier = None\n",
    "    CatBoostRegressor = None\n",
    "\n",
    "# Notebook UI/Display\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Useful helpers\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "# Scikit-Learn: Data & Preprocessing\n",
    "from sklearn.datasets import fetch_openml, load_breast_cancer\n",
    "\n",
    "# Scikit-Learn: Models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# Optional boosters\n",
    "try:\n",
    "    from xgboost import XGBClassifier, XGBRegressor\n",
    "except Exception:\n",
    "    XGBClassifier = None\n",
    "    XGBRegressor = None\n",
    "\n",
    "# This transformer will be used to handle categorical features for the baseline models\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "column_transformer = make_column_transformer((\n",
    "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    make_column_selector(dtype_include=[\"object\", \"category\"]),\n",
    "), remainder=\"passthrough\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035330ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabPFN not available in this environment; skipping TabPFN step.\n"
     ]
    }
   ],
   "source": [
    "# TabPFN integration cell (isolated) - uses fit_and_eval helper and extra sanity checks; does not modify global preds/results_df\n",
    "if not globals().get('tabpfn_available', False):\n",
    "    print('TabPFN not available in this environment; skipping TabPFN step.')\n",
    "else:\n",
    "    try:\n",
    "        from tabpfn import TabPFNClassifier\n",
    "        from tabpfn.utils import infer_categorical_features\n",
    "    except Exception as e:\n",
    "        print('TabPFN import failed at runtime:', e)\n",
    "        TabPFNClassifier = None\n",
    "\n",
    "    if TabPFNClassifier is None:\n",
    "        print('TabPFN not available; skipping.')\n",
    "    else:\n",
    "        # local results and preds\n",
    "        import pandas as _pd\n",
    "        preds_tabpfn = None\n",
    "        results_tabpfn = _pd.DataFrame()  # will construct row safely below\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                cat_ix = infer_categorical_features(X_train)\n",
    "                print('Inferred categorical feature indices using tabpfn helper:', cat_ix)\n",
    "            except Exception:\n",
    "                cat_cols = list(X_train.select_dtypes(include=['object', 'category']).columns)\n",
    "                cat_ix = [list(X_train.columns).index(c) for c in cat_cols] if len(cat_cols) > 0 else None\n",
    "                print('Fallback categorical indices:', cat_ix)\n",
    "\n",
    "            try:\n",
    "                tpfn_pipe = TabPFNClassifier(device='auto', model_path='auto', categorical_features_indices=cat_ix)\n",
    "            except TypeError:\n",
    "                try:\n",
    "                    tpfn_pipe = TabPFNClassifier(device='auto', model_path='auto', categorical_features=cat_ix)\n",
    "                except TypeError:\n",
    "                    tpfn_pipe = TabPFNClassifier(device='auto', model_path='auto')\n",
    "\n",
    "            # Try to fit and eval; allow numpy fallback\n",
    "            try:\n",
    "                res = fit_and_eval('tabpfn', tpfn_pipe)\n",
    "            except Exception as e_fit:\n",
    "                print('TabPFN fit with DataFrame inputs failed:', e_fit)\n",
    "                tpfn_pipe = TabPFNClassifier(device='auto', model_path='auto')\n",
    "                res = fit_and_eval('tabpfn', tpfn_pipe, X_train=X_train.values, X_test=X_test.values, y_train=y_train.values, y_test=y_test.values)\n",
    "                print('Retried TabPFN with numpy arrays')\n",
    "\n",
    "            # Sanity checks on outputs and robust assignment\n",
    "            proba = res.get('proba')\n",
    "            preds_bin = res.get('preds_bin')\n",
    "            import numpy as _np\n",
    "\n",
    "            # helper to align prediction arrays with X_test / y_test\n",
    "            def _align_preds(arr, X_ref, y_ref=None):\n",
    "                a = _np.asarray(arr).ravel()\n",
    "                n_a = len(a)\n",
    "                n_ref = len(X_ref)\n",
    "                if n_a == n_ref:\n",
    "                    idx = getattr(X_ref, 'index', None)\n",
    "                    return _pd.Series(a, index=idx, name='tabpfn'), a, None\n",
    "                # mismatch: trim to min length and warn\n",
    "                min_len = min(n_a, n_ref)\n",
    "                print(f'Warning: TabPFN produced {n_a} predictions but X_test has {n_ref} rows; trimming to {min_len} to align for metrics.')\n",
    "                idx = (X_ref.index[:min_len] if hasattr(X_ref, 'index') else None)\n",
    "                return _pd.Series(a[:min_len], index=idx, name='tabpfn'), a[:min_len], ('trimmed', n_a, n_ref)\n",
    "\n",
    "            # defensive function to finalize metrics into a one-row DataFrame\n",
    "            def _finalize_metrics(metrics_dict):\n",
    "                return _pd.DataFrame([metrics_dict], index=['tabpfn'])\n",
    "\n",
    "            n_test = len(X_test)\n",
    "            MIN_PRED_FRACTION = 0.01  # require at least 1% of test size, or MIN_PRED_ABS\n",
    "            MIN_PRED_ABS = 100\n",
    "            min_expected = max(int(MIN_PRED_FRACTION * n_test), MIN_PRED_ABS)\n",
    "\n",
    "            if proba is not None:\n",
    "                preds_series, p_aligned, info = _align_preds(proba, X_test, y_test)\n",
    "                preds_tabpfn = preds_series\n",
    "                y_aligned = _np.asarray(y_test).ravel()\n",
    "                if info is not None:\n",
    "                    # trim y to same length\n",
    "                    y_aligned = y_aligned[:len(p_aligned)]\n",
    "\n",
    "                # if predictions are much shorter than expected, skip computing metrics to avoid misleading results\n",
    "                if len(p_aligned) < min_expected:\n",
    "                    print(f\"TabPFN returned only {len(p_aligned)} preds vs {n_test} rows; below threshold ({min_expected}) — skipping metric computation and marking as NaN.\")\n",
    "                    metrics = {'accuracy': float('nan'), 'f1': float('nan'), 'roc_auc': float('nan'), 'pr_auc': float('nan')}\n",
    "                    results_tabpfn = _finalize_metrics(metrics)\n",
    "                else:\n",
    "                    # check degenerate probabilities\n",
    "                    if len(set(p_aligned)) <= 1:\n",
    "                        print('Warning: TabPFN returned degenerate probability array (all values equal); metrics will be NaN.')\n",
    "                        metrics = {'accuracy': float('nan'), 'f1': float('nan'), 'roc_auc': float('nan'), 'pr_auc': float('nan')}\n",
    "                        results_tabpfn = _finalize_metrics(metrics)\n",
    "                    else:\n",
    "                        from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "                        preds_bin_calc = (p_aligned >= 0.5).astype(int)\n",
    "                        metrics = {\n",
    "                            'accuracy': float(accuracy_score(y_aligned, preds_bin_calc)),\n",
    "                            'f1': float(f1_score(y_aligned, preds_bin_calc)),\n",
    "                            'roc_auc': float(roc_auc_score(y_aligned, p_aligned)) if len(set(p_aligned)) > 1 else float('nan'),\n",
    "                            'pr_auc': float(average_precision_score(y_aligned, p_aligned)) if len(set(p_aligned)) > 1 else float('nan'),\n",
    "                        }\n",
    "                        results_tabpfn = _finalize_metrics(metrics)\n",
    "            else:\n",
    "                # hard labels path\n",
    "                preds_series, p_aligned, info = _align_preds(preds_bin, X_test, y_test)\n",
    "                preds_tabpfn = preds_series\n",
    "                y_aligned = _np.asarray(y_test).ravel()\n",
    "                if info is not None:\n",
    "                    y_aligned = y_aligned[:len(p_aligned)]\n",
    "                    print('Adjusted y_test length to match predictions for metric computation')\n",
    "\n",
    "                # if predictions are much shorter than expected, skip\n",
    "                if len(p_aligned) < min_expected:\n",
    "                    print(f\"TabPFN returned only {len(p_aligned)} preds vs {n_test} rows; below threshold ({min_expected}) — skipping metric computation and marking as NaN.\")\n",
    "                    metrics = {'accuracy': float('nan'), 'f1': float('nan'), 'roc_auc': float('nan'), 'pr_auc': float('nan')}\n",
    "                    results_tabpfn = _finalize_metrics(metrics)\n",
    "                else:\n",
    "                    # check exact match to detect leakage\n",
    "                    if _np.array_equal(_np.asarray(p_aligned).ravel(), y_aligned):\n",
    "                        print('Warning: TabPFN hard-label predictions exactly match y_test — suspect leakage or mis-shape. Results marked as NaN.')\n",
    "                        metrics = {'accuracy': float('nan'), 'f1': float('nan'), 'roc_auc': float('nan'), 'pr_auc': float('nan')}\n",
    "                        results_tabpfn = _finalize_metrics(metrics)\n",
    "                    else:\n",
    "                        from sklearn.metrics import accuracy_score, f1_score\n",
    "                        metrics = {\n",
    "                            'accuracy': float(accuracy_score(y_aligned, p_aligned)),\n",
    "                            'f1': float(f1_score(y_aligned, p_aligned)),\n",
    "                            'roc_auc': float('nan'),\n",
    "                            'pr_auc': float('nan')\n",
    "                        }\n",
    "                        results_tabpfn = _finalize_metrics(metrics)\n",
    "\n",
    "            # Save artifacts only for TabPFN\n",
    "            artifacts.mkdir(exist_ok=True)\n",
    "            try:\n",
    "                if preds_tabpfn is not None:\n",
    "                    preds_tabpfn.to_csv(artifacts / 'tabpfn_preds.csv')\n",
    "                results_tabpfn.to_csv(artifacts / 'tabpfn_results.csv')\n",
    "                print('Saved TabPFN artifacts to', artifacts)\n",
    "            except Exception as e_save:\n",
    "                print('Could not save TabPFN artifacts:', e_save)\n",
    "\n",
    "            print('TabPFN isolated metrics:')\n",
    "            display(results_tabpfn)\n",
    "            print('TabPFN preds head:')\n",
    "            display((preds_tabpfn.head() if preds_tabpfn is not None else 'No preds'))\n",
    "\n",
    "        except Exception as e:\n",
    "            # helpful debug output\n",
    "            print('TabPFN fit/predict failed:', e)\n",
    "            try:\n",
    "                print('res (debug):', {k: (type(v), getattr(v, 'shape', None), len(v) if hasattr(v, '__len__') else None) for k, v in (res.items() if isinstance(res, dict) else [])})\n",
    "            except Exception:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
